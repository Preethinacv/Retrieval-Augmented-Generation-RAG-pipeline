This project demonstrates an End-to-End Retrieval-Augmented Generation (RAG) pipeline using:

ğŸ§  Groq's LLaMA3 for blazing-fast inference

ğŸ“„ LangChain for document loading, splitting, and embedding

ğŸ“¦ ObjectBox as a local vector database

âš¡ Streamlit for a lightweight, interactive frontend
